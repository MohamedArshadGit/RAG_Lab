{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a51b5c",
   "metadata": {},
   "source": [
    "This Python code implements a Retrieval-Augmented Generation (RAG) pipeline that combines semantic embeddings with keyword-based ranking to answer questions over a custom knowledge base.\n",
    "\n",
    "Dense Retrieval: Uses HuggingFaceEmbeddings and Chroma to capture semantic meaning of documents.\n",
    "\n",
    "Sparse Retrieval (BM25): Uses BM25Retriever to rank documents based on term frequency, inverse document frequency, and length normalization.\n",
    "\n",
    "Ensemble Retrieval: Combines dense and sparse retrievers via EnsembleRetriever with configurable weights (e.g., 0.7 dense, 0.3 sparse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64f5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever # is to combine both the retrievers\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5def7",
   "metadata": {},
   "source": [
    "BM25 = keyword-based document ranking using term frequency, inverse document frequency, and length normalization to score relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db41d25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2393db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key =os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c1a59",
   "metadata": {},
   "source": [
    "Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f730118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path =r\"C:\\Users\\Mohamed Arshad\\Downloads\\My_RAG_Lab\\llm_engineering\\RAG\\knowledge-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6dcbabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs loaded with 76 documents\n"
     ]
    }
   ],
   "source": [
    "loader =DirectoryLoader(path=root_path,\n",
    "                        glob=\"**/*.md\",\n",
    "                        loader_cls=TextLoader,\n",
    "                        loader_kwargs={\"encoding\":\"utf-8\"})\n",
    "\n",
    "try:\n",
    "    docs=loader.load()\n",
    "    print(f\"docs loaded with {len(docs)} documents\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"error occured {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23354be",
   "metadata": {},
   "source": [
    "Create Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f448e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter =RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks =text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d5e72",
   "metadata": {},
   "source": [
    "Initialize Dense Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca80165",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model =HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-V2\")\n",
    "dense_vector_store = Chroma.from_documents(documents=docs,embedding=embedding_model)\n",
    "dense_retreiver =dense_vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd06c67",
   "metadata": {},
   "source": [
    "Initialize Sparse Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2046f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_retreiver = BM25Retriever.from_documents(documents=chunks,k=3)\n",
    "sparse_retreiver.k=3 #top 3 documents to retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95716e01",
   "metadata": {},
   "source": [
    "Combine Ensemble Retreiver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb44a8d",
   "metadata": {},
   "source": [
    "Mostly semantic queries (concepts, paraphrases, open-ended questions) → more weight on dense.\n",
    "\n",
    "Mostly factual or keyword-heavy queries → more weight on sparse/BM25.\n",
    "\n",
    "Mixed queries → start with 0.7 dense / 0.3 sparse, then tweak based on results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9577e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retreiver =EnsembleRetriever(retrievers=[dense_retreiver,sparse_retreiver],\n",
    "weights=[0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58c98d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001DE79267FB0>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000001DE78D40530>, k=3)], weights=[0.7, 0.3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff86c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt =PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question based on the context below\n",
    "\n",
    "    Context:{context}\n",
    "\n",
    "    Question: {input}\n",
    "\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b7e44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatOpenAI(model='gpt-4.1-nano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c59d0be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001DE79267FB0>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000001DE78D40530>, k=3)], weights=[0.7, 0.3]), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\n    Answer the question based on the context below\\n\\n    Context:{context}\\n\\n    Question: {input}\\n\\n    ')\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001DE81365F70>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DE81367080>, root_client=<openai.OpenAI object at 0x000001DE811B1700>, root_async_client=<openai.AsyncOpenAI object at 0x000001DE813668D0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stuff document chain\n",
    "document_chain =create_stuff_documents_chain(llm=llm,prompt=Prompt)\n",
    "\n",
    "# create full rag chain\n",
    "rag_chain = create_retrieval_chain(retriever=hybrid_retreiver,combine_docs_chain=document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25526065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Maxine received the prestigious IIOTY Innovator of the Year (IIOTY 2023) award in 2023./n\n",
      "\n",
      " Doc 1 :# HR Record\n",
      "\n",
      "# Alex Chen\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth:** March 15, 1990\n",
      "- **Job Title:** Backend Software Engineer\n",
      "- **Location:** San Francisco, California\n",
      "- **Current Salary:** $115,000  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **April 2020:** Joined Insurellm as a Junior Backend Developer. Focused on building APIs to enhance customer data security.\n",
      "- **October 2021:** Promoted to Backend Software Engineer. Took on leadership for a key project developing a microservices architecture to support the company's growing platform.\n",
      "- **March 2023:** Awarded the title of Senior Backend Software Engineer due to exemplary performance in scaling backend services, reducing downtime by 30% over six months.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:**  \n",
      "  - Completed onboarding successfully.  \n",
      "  - Met expectations in delivering project milestones.  \n",
      "  - Received positive feedback from the team leads.\n",
      "\n",
      "- **2021:**  \n",
      "  - Achieved a 95% success rate in project delivery timelines.  \n",
      "  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \n",
      "\n",
      "- **2022:**  \n",
      "  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \n",
      "  - Conducted training sessions for junior developers, fostering knowledge sharing.  \n",
      "\n",
      "- **2023:**  \n",
      "  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \n",
      "  - Contributed to the company’s transition to a cloud-based infrastructure.  \n",
      "  - Received an overall performance rating of 4.8/5.\n",
      "\n",
      "## Compensation History\n",
      "- **2020:** Base Salary: $80,000  \n",
      "- **2021:** Base Salary Increase to $90,000; Received a performance bonus of $5,000.  \n",
      "- **2022:** Base Salary Increase to $100,000; Performance bonus of $7,500 due to exceptional project outcomes.  \n",
      "- **2023:** Base Salary Increase to $115,000; Performance bonus of $10,000 for leading pivotal projects.\n",
      "\n",
      "## Other HR Notes\n",
      "- Participates regularly in Insurellm's Diversity & Inclusion initiatives, championing tech accessibility for underrepresented communities.\n",
      "- Completed several certifications in cloud architecture and DevOps, contributing to professional growth.\n",
      "- Plans for a professional development course in AI and machine learning to further enhance backend capabilities in Insurellm's offerings.\n",
      "- Acknowledged for volunteer efforts in local tech meetups, bringing seasoned engineers to mentor aspiring coders.  \n",
      "\n",
      "Alex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.\n",
      "\n",
      " Doc 2 :# HR Record\n",
      "\n",
      "# Robert Chen\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth:** February 28, 1983\n",
      "- **Job Title:** Senior Full Stack Engineer\n",
      "- **Location:** San Francisco, California\n",
      "- **Current Salary:** $152,000\n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **January 2016 - Present:** Senior Full Stack Engineer\n",
      "  - Technical lead for Homellm home insurance portal\n",
      "  - Architects full-stack solutions using React, Node.js, and PostgreSQL\n",
      "  - Mentors team of 6 engineers\n",
      "  - Led 3 major platform releases\n",
      "\n",
      "- **June 2012 - December 2015:** Full Stack Developer at WebSolutions Inc.\n",
      "  - Built web applications for enterprise clients\n",
      "  - Worked with various JavaScript frameworks and backend technologies\n",
      "\n",
      "- **August 2008 - May 2012:** Software Engineer at TechStartup\n",
      "  - Developed features for SaaS platform\n",
      "  - Gained experience across full technology stack\n",
      "\n",
      "## Annual Performance History\n",
      "- **2023:** Rating: 4.8/5\n",
      "  *Exceptional performance. Led critical platform modernization project. Outstanding technical leadership and mentorship.*\n",
      "\n",
      "- **2022:** Rating: 4.6/5\n",
      "  *Exceeded expectations. Delivered major features ahead of schedule with high quality. Strong team collaboration.*\n",
      "\n",
      "- **2021:** Rating: 4.4/5\n",
      "  *Strong performance with successful migration to microservices architecture. Effective technical decision-making.*\n",
      "\n",
      "- **2020:** Rating: 4.2/5\n",
      "  *Good performance maintaining productivity during remote transition. Supported team well through change.*\n",
      "\n",
      "- **2019:** Rating: 4.5/5\n",
      "  *Excellent year with successful Homellm rewrite. Strong architectural contributions.*\n",
      "\n",
      "- **2018:** Rating: 4.3/5\n",
      "  *Solid performance with consistent high-quality delivery. Growing into technical leadership role.*\n",
      "\n",
      "- **2017:** Rating: 4.1/5\n",
      "  *Good performance. Expanding expertise across full stack and taking on more complex features.*\n",
      "\n",
      "- **2016:** Rating: 4.0/5\n",
      "  *Strong start at Insurellm. Quick to learn domain and contribute effectively.*\n",
      "\n",
      "## Compensation History\n",
      "- **2023:** Base Salary: $152,000 + Bonus: $28,000\n",
      "- **2022:** Base Salary: $145,000 + Bonus: $25,000\n",
      "- **2021:** Base Salary: $138,000 + Bonus: $22,000\n",
      "- **2020:** Base Salary: $132,000 + Bonus: $20,000\n",
      "- **2019:** Base Salary: $125,000 + Bonus: $18,000\n",
      "- **2018:** Base Salary: $118,000 + Bonus: $15,000\n",
      "- **2017:** Base Salary: $112,000 + Bonus: $12,000\n",
      "- **2016:** Base Salary: $105,000 + Bonus: $10,000\n",
      "\n",
      "## Other HR Notes\n",
      "- **Education:** MS in Computer Science from Stanford University, BS in Computer Engineering from MIT\n",
      "- **Technical Expertise:** Expert in React, Node.js, TypeScript, PostgreSQL, AWS, microservices architecture\n",
      "- **Recognition:** Engineering Excellence Award 2023, Technical Leadership Award 2021\n",
      "- **Mentorship:** Mentored 12 engineers during tenure. Known for developing junior talent into strong contributors.\n",
      "- **Patents:** Co-inventor on 1 patent for insurance processing optimization\n",
      "- **Feedback:** World-class engineer with exceptional technical and leadership skills. Trusted advisor to engineering leadership. Critical to company's technical success.\n",
      "\n",
      "\n",
      " Doc 3 :- **January 2021 - Present**: **Senior Data Engineer**  \n",
      "  * Maxine was promoted to Senior Data Engineer after successfully leading a pivotal project that improved data retrieval times by 30%. She now mentors junior engineers and is involved in strategic data initiatives, solidifying her position as a valued asset at Insurellm. She was recognized as Insurellm Innovator of the year in 2023, receiving the prestigious IIOTY 2023 award.\n",
      "\n",
      " Doc 4 :## Compensation History\n",
      "- **2017**: $70,000 (Junior Data Engineer)  \n",
      "- **2018**: $75,000 (Junior Data Engineer)  \n",
      "- **2019**: $80,000 (Data Engineer)  \n",
      "- **2020**: $84,000 (Data Engineer)  \n",
      "- **2021**: $95,000 (Senior Data Engineer)  \n",
      "- **2022**: $110,000 (Senior Data Engineer)  \n",
      "- **2023**: $120,000 (Senior Data Engineer)  \n",
      "\n",
      "## Other HR Notes\n",
      "- Maxine participated in various company-sponsored trainings related to big data technologies and cloud infrastructure.  \n",
      "- She was recognized for her contributions with the prestigious Insurellm IIOTY Innovator Award in 2023.  \n",
      "- Maxine is currently involved in the women-in-tech initiative and participates in mentorship programs to guide junior employees.  \n",
      "- Future development areas include improving her stakeholder communication skills to ensure smoother project transitions and collaboration.\n",
      "\n",
      " Doc 5 :## Other HR Notes\n",
      "- **Education:** MS in Computer Science from University of Florida\n",
      "- **Certifications:** AWS Solutions Architect Professional, Salesforce Certified Technical Architect\n",
      "- **Languages:** Fluent in English and Spanish, frequently supports Latin American clients\n",
      "- **Recognition:** Solutions Engineer of the Year 2023\n",
      "- **Skills:** Expert in API integrations, cloud architecture, and technical sales. Strong presenter with ability to explain complex concepts to non-technical audiences.\n",
      "- **Feedback:** Top performer who combines deep technical knowledge with excellent sales acumen. Natural leader who mentors junior SEs.\n"
     ]
    }
   ],
   "source": [
    "query ={\"input\":\"who received the prestigious IIOTY award in 2023?\"}\n",
    "response =rag_chain.invoke(query)\n",
    "\n",
    "print(f\"Answer: {response['answer']}/n\")\n",
    "#print(response)\n",
    "\n",
    "\n",
    "for i,doc in enumerate(response['context']):\n",
    "    print(f\"\\n Doc {i+1} :{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c08151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
